{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "(train_ds, test_ds),ds_info = tfds.load('cifar10', split=['train', 'test'], as_supervised=True, with_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "def prepare_data(data): \n",
    "    #data = data.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    data = data.map(lambda img, target: ((img/255), target))\n",
    "    data = data.map(lambda img, target: (img, tf.one_hot(target, depth=10))) # no one-hot encoding\n",
    "    data = data.cache()\n",
    "    data = data.shuffle(1000)\n",
    "    data = data.batch(32)\n",
    "    data = data.prefetch(20)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_ds.apply(prepare_data)\n",
    "test_dataset = test_ds.apply(prepare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "#for i in range(25):\n",
    "#    plt.subplot(5,5,i+1)\n",
    "#    plt.xticks([])\n",
    "#    plt.yticks([])\n",
    "#    plt.grid(False)\n",
    "#    plt.imshow(train_images[i])\n",
    "#    # The CIFAR labels happen to be arrays, \n",
    "#    # which is why you need the extra index\n",
    "#    plt.xlabel(classes[train_labels[i][0]])\n",
    "#plt.show()\n",
    "#tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 16:56:40.960590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-12-04 16:56:40.960755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_iterator = train_dataset.as_numpy_iterator().next()\n",
    "print(train_iterator[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "        # layers to encode the images (both layers used for both images)\n",
    "        self.convlayer1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=( 32,32,3))\n",
    "        self.convlayer2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")\n",
    "        #self.pooling = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)\n",
    "\n",
    "\n",
    "        #self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        #self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        #self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.global_pool = tf.keras.layers.GlobalAvgPool2D()\n",
    "        \n",
    "        self.out_layer = tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, image, training=False):\n",
    "\n",
    "        x = image\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x,y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(x, training=True)\n",
    "            loss = self.loss_function(y, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(y, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self(x, training=False)\n",
    "        loss = self.loss_function(y, output)\n",
    "        self.metrics[0].update_state(y, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    return train_summary_writer, val_summary_writer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def training_loop(model, \n",
    "                train_ds, \n",
    "                test_ds, \n",
    "                start_epoch,\n",
    "                epochs,\n",
    "                train_summary_writer, \n",
    "                val_summary_writer, \n",
    "                save_path):\n",
    "\n",
    "    # 1. iterate over epochs\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # 2. train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            print(data)\n",
    "            metrics = model.train_step(data) # we save to metrics because we want to print it and tensorboard\n",
    "\n",
    "        ## Training data\n",
    "        # 3. log and print training metrics\n",
    "        with train_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "        \n",
    "        #print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # 4. reset metric objects for next epch\n",
    "        model.reset_metrics()\n",
    "\n",
    "        #####################################################\n",
    "\n",
    "        ## Validation data\n",
    "        # 5. evaluate on validation data\n",
    "        for data in test_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "        # 6. log validation metrics\n",
    "        with val_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "            \n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        # 7. reset metric objects\n",
    "        model.reset_metrics()\n",
    "        \n",
    "    # 8. save model weights if save_path is given\n",
    "    if save_path:\n",
    "        model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]2022-12-04 16:56:41.161356: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 32, 3), dtype=uint8, numpy=\n",
      "array([[[143,  96,  70],\n",
      "        [141,  96,  72],\n",
      "        [135,  93,  72],\n",
      "        ...,\n",
      "        [ 96,  37,  19],\n",
      "        [105,  42,  18],\n",
      "        [104,  38,  20]],\n",
      "\n",
      "       [[128,  98,  92],\n",
      "        [146, 118, 112],\n",
      "        [170, 145, 138],\n",
      "        ...,\n",
      "        [108,  45,  26],\n",
      "        [112,  44,  24],\n",
      "        [112,  41,  22]],\n",
      "\n",
      "       [[ 93,  69,  75],\n",
      "        [118,  96, 101],\n",
      "        [179, 160, 162],\n",
      "        ...,\n",
      "        [128,  68,  47],\n",
      "        [125,  61,  42],\n",
      "        [122,  59,  39]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[187, 150, 123],\n",
      "        [184, 148, 123],\n",
      "        [179, 142, 121],\n",
      "        ...,\n",
      "        [198, 163, 132],\n",
      "        [201, 166, 135],\n",
      "        [207, 174, 143]],\n",
      "\n",
      "       [[187, 150, 117],\n",
      "        [181, 143, 115],\n",
      "        [175, 136, 113],\n",
      "        ...,\n",
      "        [201, 164, 132],\n",
      "        [205, 168, 135],\n",
      "        [207, 171, 139]],\n",
      "\n",
      "       [[195, 161, 126],\n",
      "        [187, 153, 123],\n",
      "        [186, 151, 128],\n",
      "        ...,\n",
      "        [212, 177, 147],\n",
      "        [219, 185, 155],\n",
      "        [221, 187, 157]]], dtype=uint8)>, <tf.Tensor: shape=(), dtype=int64, numpy=7>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/ipykernel_12063/1901598850.py\", line 55, in train_step  *\n        output = self(x, training=True)\n    File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).layers, None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'layer'})\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py\", line 22, in loop_body\n        x = ag__.converted_call(ag__.ld(layer), (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"cnn_8\" \"                 f\"(type CNN).\n    \n    in user code:\n    \n        File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/ipykernel_12063/1901598850.py\", line 33, in call  *\n            x = layer(x)\n        File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"conv2d_16\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 32, 3)\n    \n    \n    Call arguments received by layer \"cnn_8\" \"                 f\"(type CNN):\n      • image=tf.Tensor(shape=(32, 32, 3), dtype=uint8)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [68], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m train_summary_writer, val_summary_writer \u001b[39m=\u001b[39m create_summary_writers(config_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRUN4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# 3. pass arguments to training loop function\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m training_loop(model\u001b[39m=\u001b[39;49mcnn,\n\u001b[1;32m     12\u001b[0m     train_ds\u001b[39m=\u001b[39;49mtrain_ds,\n\u001b[1;32m     13\u001b[0m     test_ds\u001b[39m=\u001b[39;49mtest_ds,\n\u001b[1;32m     14\u001b[0m     start_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     train_summary_writer\u001b[39m=\u001b[39;49mtrain_summary_writer,\n\u001b[1;32m     17\u001b[0m     val_summary_writer\u001b[39m=\u001b[39;49mval_summary_writer,\n\u001b[1;32m     18\u001b[0m     save_path\u001b[39m=\u001b[39;49msave_path_subtask)\n",
      "Cell \u001b[0;32mIn [67], line 17\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_ds, test_ds, start_epoch, epochs, train_summary_writer, val_summary_writer, save_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(train_ds, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(data)\n\u001b[0;32m---> 17\u001b[0m     metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data) \u001b[39m# we save to metrics because we want to print it and tensorboard\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m## Training data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# 3. log and print training metrics\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m train_summary_writer\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m     22\u001b[0m     \u001b[39m# for scalar metrics:\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/iannwtf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filekh39nwgp.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     10\u001b[0m (x, y) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(data)\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 12\u001b[0m     output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope)\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mloss_function, (ag__\u001b[39m.\u001b[39mld(y), ag__\u001b[39m.\u001b[39mld(output)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, image, training)\u001b[0m\n\u001b[1;32m     22\u001b[0m     x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(layer), (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     23\u001b[0m layer \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlayers, \u001b[39mNone\u001b[39;49;00m, loop_body, get_state, set_state, (\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m,), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[1;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py:22\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mnonlocal\u001b[39;00m x\n\u001b[1;32m     21\u001b[0m layer \u001b[39m=\u001b[39m itr\n\u001b[0;32m---> 22\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(layer), (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/ipykernel_12063/1901598850.py\", line 55, in train_step  *\n        output = self(x, training=True)\n    File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).layers, None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'layer'})\n    File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/__autograph_generated_filenxmbfpf6.py\", line 22, in loop_body\n        x = ag__.converted_call(ag__.ld(layer), (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"cnn_8\" \"                 f\"(type CNN).\n    \n    in user code:\n    \n        File \"/var/folders/2q/hwnn9141093b7bkbnd4bm7tc0000gn/T/ipykernel_12063/1901598850.py\", line 33, in call  *\n            x = layer(x)\n        File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/Users/leonackermann/miniforge3/envs/iannwtf/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"conv2d_16\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 32, 3)\n    \n    \n    Call arguments received by layer \"cnn_8\" \"                 f\"(type CNN):\n      • image=tf.Tensor(shape=(32, 32, 3), dtype=uint8)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "# 1. instantiate model\n",
    "cnn = CNN()\n",
    "\n",
    "# 2. choose a path to save the weights\n",
    "save_path_subtask = \"RUN4\"\n",
    "\n",
    "train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"RUN4\")\n",
    "\n",
    "\n",
    "# 3. pass arguments to training loop function\n",
    "training_loop(model=cnn,\n",
    "    train_ds=train_ds,\n",
    "    test_ds=test_ds,\n",
    "    start_epoch=0,\n",
    "    epochs=10,\n",
    "    train_summary_writer=train_summary_writer,\n",
    "    val_summary_writer=val_summary_writer,\n",
    "    save_path=save_path_subtask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  multiple                 0 (unused)\n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_18 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_19 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de1a73bac91e79fc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de1a73bac91e79fc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('iannwtf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3449bbb043929c6f13b514689ff91c66257e0787e2d8bb0eba8270d3f40eacf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
