{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ighIhhiLaBtR"
      },
      "source": [
        "## Practical Exercise 1: word2vec\n",
        "By Joline Janz and Frederik Wollatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpTQUaW0co-k"
      },
      "source": [
        "Each Notebook will contribute equaly to your final grade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCmr1p64aBtW"
      },
      "source": [
        "This practical Exercise is presented as an IPython Notebook, with the code written for recent versions of **Python 3**. \n",
        "\n",
        "To execute a notebook cell, press `shift-enter`. The return value of the last command will be displayed, if it is not `None`.\n",
        "\n",
        "Potentially useful library documentation, references, and resources:\n",
        "\n",
        "* IPython notebooks: <https://ipython.org/ipython-doc/3/notebook/notebook.html#introduction>\n",
        "* Numpy numerical array library: <https://docs.scipy.org/doc/>\n",
        "* Gensim's word2vec: <https://radimrehurek.com/gensim/models/word2vec.html>\n",
        "* Bokeh interactive plots: <http://bokeh.pydata.org/en/latest/> (we provide plotting code here, but click the thumbnails for more examples to copy-paste)\n",
        "* scikit-learn ML library (aka `sklearn`): <http://scikit-learn.org/stable/documentation.html>\n",
        "* nltk NLP toolkit: <http://www.nltk.org/>\n",
        "* tutorial for processing xml in python using `lxml`: <http://lxml.de/tutorial.html> (we did this for you below, but in case you need it in the future)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzHhEXkWco-r"
      },
      "source": [
        "In this Notebook you will learn the basics on how to construct a word-embedding. As you recall from the lecture, word-embeddings are a type of word representation that allows words with similar meaning to have a similar representation. To do this, words are represented as real-valued vectors in a predefined vector space. Additionally, you will also learn how to use some basic NLP tools like tokenization and regular Expressions!\n",
        "Good Luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "569W6MImaBtX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rsgimgrUaBtd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "        .bk-notebook-logo {\n",
              "            display: block;\n",
              "            width: 20px;\n",
              "            height: 20px;\n",
              "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
              "        }\n",
              "    </style>\n",
              "    <div>\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
              "        <span id=\"p1001\">Loading BokehJS ...</span>\n",
              "    </div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.0.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.0.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show, output_file\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ofHeuGejaZHs"
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    import nltk\n",
        "except:\n",
        "    import sys #Here we install nltk. You only have to execute this cell once!\n",
        "    !{sys.executable} -m pip install nltk \n",
        "    import nltk\n",
        "    nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to\n",
            "[nltk_data]    |     /Users/leonackermann/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haav4K7YaBti"
      },
      "source": [
        "### Part 0: Load the TED dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_L2VA4Mco-2"
      },
      "source": [
        "As input we need a large amount of text data. We will use the TED database, which are the transcripts of Ted Talks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "stf464BBaBtj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import lxml.etree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          }
        },
        "id": "2GPN2XwC-kwo",
        "outputId": "d7a315cb-2485-40b5-f722-b6aee996fcf2"
      },
      "outputs": [],
      "source": [
        "# Upload the dataset if it's not already there: this may take a minute as it is 75MB\n",
        "if not os.path.isfile('ted_en-20160408.zip'):\n",
        "  from google.colab import files\n",
        "  # select the file \"ted_en-20160408.zip\" from your local drive here\n",
        "  uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0oWf1JkvaBtr"
      },
      "outputs": [],
      "source": [
        "# For now, we're only interested in the subtitle text, so let's extract that from the XML:\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
        "del doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UVfpExaBtu"
      },
      "source": [
        "### Part 1: Preprocessing\n",
        "\n",
        "Before using our text, we need to preprocess it. Therefore, we bring it into a form that is predictable and analyzable. We attempt to clean up the raw subtitles a bit, so that we get only complete sentences. The following substring shows examples of what we're trying to get rid of. Since it's hard to define precisely what we want to get rid of, we'll just use some simple heuristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKWHxHG7bkWa"
      },
      "source": [
        "<h4>Execercise 1.1 (2 Points)</h4> \n",
        "Before we work with the data we should have a look at it. We already marked some areas for you, that need to be cleaned. You do not have to code anything here, you just have to become aware of sensitive preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGpx6RFzaBtv",
        "outputId": "b99241bc-d2b2-41d1-e732-817286a256d1",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? (Ball squeaks) Wow.\n",
            "Laura Schulz: Told you. (Laughs)\n",
            "\n",
            "You will earn 10% of any gold \n"
          ]
        }
      ],
      "source": [
        "#Have a look at the output of this code, to see some examples\n",
        "i = input_text.find(\"Hyowon Gweon: See this?\")\n",
        "print(input_text[i:i+145])\n",
        "\n",
        "\n",
        "i = input_text.find(\"You will earn\")\n",
        "print(input_text[i:i+30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y7gtjkWcJ-2"
      },
      "source": [
        "For example the parenthesized strings like \"(Ball squeaks)\" and symbols like % could have a negative impact on the word embeddings. Name at least two more problematic sections and how you would solve them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqC68N5Yco_E"
      },
      "source": [
        "<b>Your Solution:</b> \n",
        "<br>- Parenthesized Strings\n",
        "<br>- Percent-Symbol\n",
        "<br>-\n",
        "<br>-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH2seZr2aBt1"
      },
      "source": [
        "<h4>Exercise 1.2 (2 Points)</h4>\n",
        "Let's start by removing all parenthesized strings using a regex:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u3YXkh5aBt1",
        "outputId": "030d9650-24a6-4171-9b4d-fc227d68834a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before\n",
            "Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? (\n",
            "after\n",
            "Hyowon Gweon: See this?  Did you see that?  Cool. See this one?  Wow.\n",
            "Laura Schulz: Told you.\n"
          ]
        }
      ],
      "source": [
        "i = input_text.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"before\")\n",
        "print(input_text[i:i+93])\n",
        "\n",
        "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text) #Identifies everything in parenthesis and replaces it with \"\"\n",
        "\n",
        "\n",
        "#you can use this to verify\n",
        "i = input_text_noparens.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"after\")\n",
        "print(input_text_noparens[i:i+93])\n",
        "\n",
        "#We won't worry about the irregular spaces since we'll later split the text into sentences and tokenize it anyway."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtwPNpChdjww"
      },
      "source": [
        "Try it yourself: Replace every percentage Symbol with the word \"percent\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6o6oEW0AdiDY",
        "outputId": "18c3c00a-e32f-454f-8909-cf71b5fffe5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before\n",
            "You will earn 10% of any gold \n",
            "after\n",
            "You will earn 10 percent of any gold \n"
          ]
        }
      ],
      "source": [
        "i = input_text_noparens.find(\"You will earn\")\n",
        "print(\"before\")\n",
        "print(input_text_noparens[i:i+30])\n",
        "\n",
        "#Your implementation goes here!\n",
        "input_text_clean = re.sub(r'%', ' percent', input_text) #Identifies every % symbol and replaces it with \"\"\n",
        "\n",
        "\n",
        "i = input_text_clean.find(\"You will earn\")\n",
        "print(\"after\")\n",
        "print(input_text_clean[i:i+37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67ZOyc_9e2aS"
      },
      "source": [
        "<h4>Exercise 1.3 (4 Points)</h4>\n",
        "Now you have learned how to use RegEx to your advantage and have Identified potential parts of the text, that we want to eliminate. We have already implented how to remove all parenthesized strings. Now we want to replace every number in the text with its respectiv string. E.g. 10 -> ten ; \n",
        "42 -> forty-two\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "S6NKj6fNfXMQ",
        "outputId": "2b2f35da-0ffd-414b-a604-d458b73f3313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before\n",
            "You will earn 10 percent of any gold \n",
            "<class 'str'>\n",
            "after\n",
            "You will earn ten percent of any gold\n"
          ]
        }
      ],
      "source": [
        "from num2words import num2words\n",
        "\n",
        "i = input_text_clean.find(\"You will earn\") #find problematic parts\n",
        "print(\"before\")\n",
        "print(input_text_clean[i:i+37]) #and show them\n",
        "print(type(input_text_clean))\n",
        "\n",
        "#Your implementation here\n",
        "all_numbers_in_digits = re.findall(\"[0-9]+\", input_text_clean)\n",
        "all_numbers_in_text = {number:num2words(number) for number in all_numbers_in_digits}\n",
        "def number_to_word(matchobj):\n",
        "    return all_numbers_in_text[matchobj.group(0)]\n",
        "input_text_clean = re.sub(r\"[0-9]+\", number_to_word, input_text_clean )\n",
        "\n",
        "i = input_text_clean.find(\"You will earn\") #validate your method\n",
        "print(\"after\")\n",
        "print(input_text_clean[i:i+37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJEtm8eOaBt9"
      },
      "source": [
        "<h4>Exercise 1.4 (4 Points)</h4>\n",
        "What does this block of code do? Identify one possible flaw. You dont have to code anything here!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFUCfLOkco_K",
        "outputId": "5da7730c-fb61-405d-9c23-3ca16f374b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before:\n",
            "k them. But let's see what the baby does.\n",
            "(Video) Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? \n",
            "after:\n",
            " or whack them. But let's see what the baby does. See this? (Ball squeaks) Did you see that? (Ball squeak\n"
          ]
        }
      ],
      "source": [
        "i = input_text_clean.find(\"Hyowon Gweon: See this?\")\n",
        "print(\"before:\")\n",
        "print(input_text_clean[i-50:i+92])\n",
        "\n",
        "X = []\n",
        "for line in input_text_clean.split('\\n'): #take each line of input_text_clean, because we split it at each linebreak\n",
        "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
        "    X.extend(m.groupdict()['postcolon'])\n",
        "input_text_clean2=\"\".join(X)\n",
        "\n",
        "\n",
        "i = input_text_clean2.find(\"See this?\")\n",
        "print(\"after:\")\n",
        "print(input_text_clean2[i-50:i+55])"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ix75Rnrrco_M"
      },
      "source": [
        "Your Answer goes here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX5lFA4XijPm"
      },
      "source": [
        "<h4>Exercise 1.5 (6 Points)</h4>\n",
        "\n",
        "To build our embedding we need to tokenize every single word. Therefore we first need to split the text into sentences and after that into words. \n",
        "Try it yourself or use the NLTK-Tools build for this (https://www.kite.com/python/docs/nltk.word_tokenize + https://www.kite.com/python/docs/nltk.sent_tokenize).\n",
        "To make it easier to build our Embedding we should also delete every character that is not a letter. Additionally, we could lower vocabulary count. A way to do this is by converting capital characters to lower case characters.\n",
        "\n",
        "Split your text into sentences and save them in the array `sentences_strings_ted`.\n",
        "Save one variabale `tokens` with all the tokens in the text and one array named `sentences_ted` that contains an array for every sentence, with all the tokenized words of that sentence.<br><br>\n",
        "Example:<br>\n",
        "If the Text looks like this: \"I love cake. You have to be honest, you love it too!\", the variables look like:<br><br>\n",
        "sentences_strings_ted=['I love cake.', 'You have to be honest, you love it too!']<br>\n",
        "sentences_ted=[['i', 'love', 'cake'], ['you', 'have', 'to', 'be', 'honest', 'you', 'love', 'it', 'too']]<br>\n",
        "tokens=['i', 'love', 'cake', 'you', 'have', 'to', 'be', 'honest', 'you', 'love', 'it', 'too']<br>\n",
        "\n",
        "\n",
        "Apply this to `input_text_clean`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text_clean_letters = re.sub(r\"\\W^.\", \"\", input_text_clean ) # delete every non-letter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_text_clean_lower = input_text_clean_letters.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (176750117.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn [16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(input_text_clean_lower[:10000)\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
          ]
        }
      ],
      "source": [
        "print(input_text_clean_lower[:10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"here are two reasons companies fail: they only do more of the same, or they only do what's new.\", 'to me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation.']\n"
          ]
        }
      ],
      "source": [
        "sentences_strings_ted = nltk.tokenize.sent_tokenize(input_text_clean_lower)\n",
        "print(sentences_strings_ted[:2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences_ted = [nltk.word_tokenize(sentence) for sentence in sentences_strings_ted]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '.'], ['to', 'me', 'the', 'real', ',', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', ':', 'exploration', 'and', 'exploitation', '.']]\n"
          ]
        }
      ],
      "source": [
        "print(sentences_ted[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do']\n"
          ]
        }
      ],
      "source": [
        "tokens = [token for sentence in sentences_ted for token in sentence]\n",
        "print(tokens[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUiFC0I5j31i"
      },
      "source": [
        "<h4>Exercise 1.6 (1 Point)</h4>\n",
        "The good side is, that by converting all capital letters is, we reduce the volume of the vocabulary. Thereby we dont differentiate between the the words \"today\" and \"Today\". \n",
        "Can you think of any downside to this process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yt08f-sco_O"
      },
      "source": [
        "YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Fs3pzZmHHv"
      },
      "source": [
        "Now we can have a look at the processed dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooe1gfSZaBuG",
        "outputId": "9726e08b-f631-4e80-f4ef-55432eff8f19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "273205"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sentences_ted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Jwdw8QxbaBuJ",
        "outputId": "8f971b5c-f0c4-4664-8da8-5ca5b61bf1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['here', 'are', 'two', 'reasons', 'companies', 'fail', ':', 'they', 'only', 'do', 'more', 'of', 'the', 'same', ',', 'or', 'they', 'only', 'do', 'what', \"'s\", 'new', '.']\n",
            "['(', 'applause', ')']\n"
          ]
        }
      ],
      "source": [
        "print(sentences_ted[0])\n",
        "print(sentences_ted[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjkAGHjaBuN"
      },
      "source": [
        "### Part 2: Word Frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLMH0iXaBuO"
      },
      "source": [
        "<h4>Exercise 2.1 (4 Points)</h4>\n",
        "Your next task will be to store the counts of the top 1000 most frequent words in a list called `counts_ted_top1000` ! There are multiple ways to do this. You can have a look at the Counter-Function(https://docs.python.org/2/library/collections.html) or the FreqDist-Function (https://www.kite.com/python/docs/nltk.FreqDist). If you dont trust any of those you can of course build your own function.\n",
        "In the end we want an array with tupels of the structure [(WordA,FrequencyA),(WordB,FrequencyB)]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LcQzY8iWaBuP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(',', 309801), ('.', 248880), ('the', 207745), ('and', 155083), ('to', 124886), ('of', 114750), ('a', 104989), ('that', 95167), ('i', 83026), ('in', 77904), ('it', 74734), ('you', 70956), ('we', 67657), ('is', 64390), (\"'s\", 55908), ('this', 49273), ('so', 36932), ('they', 33105), ('was', 31902), ('for', 29675), ('are', 28494), ('have', 27846), ('but', 26748), ('what', 26519), ('do', 26073), ('on', 25831), ('with', 24719), ('--', 23658), ('?', 22478), ('one', 22412), (\"n't\", 22343), ('can', 21488), ('about', 21249), ('there', 21049), ('be', 20190), ('as', 19483), ('not', 19308), ('at', 19226), ('all', 18890), ('my', 17930), (\"''\", 17338), ('``', 17195), ('people', 16724), (\"'re\", 16671), ('like', 16046), ('if', 15866), ('from', 15458), (')', 15003), ('(', 14986), ('now', 14392), ('our', 14065), (':', 14006), ('he', 13995), ('an', 13917), ('just', 13897), ('these', 13881), ('or', 13841), ('when', 13280), ('because', 12881), ('very', 12368), ('me', 12296), ('out', 12048), ('by', 11867), ('them', 11593), ('how', 11565), ('know', 11488), ('going', 11364), ('up', 11130), ('had', 11091), ('more', 10907), ('would', 10579), ('were', 10533), ('think', 10463), ('who', 10447), ('see', 10175), ('your', 10094), ('their', 10031), ('which', 10024), ('here', 9895), ('really', 9675), ('get', 9378), (\"'ve\", 9261), ('then', 9224), ('two', 8942), (\"'m\", 8848), ('us', 8836), ('world', 8811), ('some', 8620), ('time', 8567), ('has', 8449), ('laughter', 8422), ('could', 8105), ('actually', 8014), ('into', 7862), ('where', 7722), ('way', 7691), ('hundred', 7689), ('did', 7668), ('will', 7618), ('things', 7538)]\n"
          ]
        }
      ],
      "source": [
        "#Your Code here\n",
        "counts_ted_top1000 = nltk.FreqDist(tokens)\n",
        "counts_ted_top1000_sorted = {key: val for key, val in sorted(counts_ted_top1000.items(), key = lambda ele: ele[1], reverse = True)}\n",
        "counts_ted_top1000tupels = [(key, value) for key, value in zip(counts_ted_top1000_sorted.keys(), counts_ted_top1000_sorted.values())]\n",
        "print(counts_ted_top1000tupels[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hti5NFdGaBuX"
      },
      "source": [
        "The following code is going to plot a histogramm of the distribution of the  top-30 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kjdE_DKLco_S",
        "outputId": "20c41b52-255b-4ec6-91d9-9ad4a3242956"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "mostfreqn=30 #Here we define how many of them we want to see in the diagramm \n",
        "frequency=[y for (x,y) in counts_ted_top1000tupels][:mostfreqn]\n",
        "word=[x for (x,y) in counts_ted_top1000tupels][:mostfreqn]\n",
        "indices = np.arange(len(counts_ted_top1000tupels[:mostfreqn]))\n",
        "plt.bar(indices, frequency, color='r')\n",
        "plt.xticks(indices, word, rotation='vertical')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vnAj55Aco_U"
      },
      "source": [
        "You can clearly see, that many of the most common words are so called stop words. Stop Words are words, that are tipically not usefull to identify what a text is about."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oRdD3e4aBud"
      },
      "source": [
        "### Part 3: Train Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp0JGmKWhrNd"
      },
      "source": [
        "Now it is time to train the modell. Gensim has an already implemented model that you can use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTA9yWtdhb6z"
      },
      "source": [
        "Using the provided modell is enough for the purposes of our notebook. If you want to dive deeper into the topic this youtube video https://www.youtube.com/watch?v=kKDYtZfriI8 could be a great guidance for you to get started. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A_t4-aiTaBue"
      },
      "outputs": [],
      "source": [
        "#This takes a moment...dont worry :D\n",
        "from gensim.models import Word2Vec\n",
        "model_ted = Word2Vec(sentences_ted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKYd7ZemaBuj"
      },
      "source": [
        "### Part 4: Ted Learnt Representations (3 Points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7VvU82AaBuj"
      },
      "source": [
        "Finding similar words: (see gensim docs for functions, that might help you https://radimrehurek.com/gensim/models/keyedvectors.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW2Gbn4Qco_a"
      },
      "source": [
        "Now lets explore what we can do with this! How does \"house\" look in our embedding?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PKtCfFD4co_b"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE\n",
        "word_vectors = model_ted.wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.00010271  0.00463678 -0.00751325 -0.00099584  0.00743177  0.00310723\n",
            " -0.00144975  0.00867777 -0.0104847   0.00202265 -0.00454901 -0.00644722\n",
            "  0.0084535   0.00292431  0.00919747 -0.00675906  0.00664399  0.00895228\n",
            " -0.00886504 -0.01028279 -0.00563356 -0.0040761  -0.00074098 -0.00933942\n",
            "  0.00791998 -0.00492829  0.00634847  0.00452818 -0.00749265  0.00552725\n",
            "  0.00772975 -0.00929325 -0.0047575  -0.0075233  -0.00912863  0.0011653\n",
            "  0.00117682  0.00272671  0.00058964 -0.00381314 -0.00574927 -0.00043863\n",
            " -0.0018731   0.00752167  0.00572764  0.00387808 -0.00088068 -0.00409778\n",
            " -0.00246557  0.00091635  0.00184205 -0.0053665  -0.00859293 -0.00805943\n",
            " -0.00884041 -0.00545929  0.00094566 -0.00591062 -0.00783178 -0.00262691\n",
            "  0.00423269 -0.00480901  0.01035926  0.00228528 -0.00930873  0.01391488\n",
            "  0.00700011  0.00802935 -0.01089624  0.00846184  0.00355627  0.00691785\n",
            "  0.00730873  0.00330168  0.00136694  0.00789375  0.00900024  0.00384574\n",
            " -0.00474471 -0.00102628 -0.00026468 -0.00862725 -0.01178012  0.00182983\n",
            " -0.00029232 -0.00796572 -0.00255857 -0.00734595  0.01105728  0.00292039\n",
            " -0.00054955  0.00636259  0.00893363 -0.00380592  0.01178508  0.0075365\n",
            "  0.00670169 -0.00144972  0.007847   -0.00837153]\n"
          ]
        }
      ],
      "source": [
        "the = word_vectors[\"the\"]\n",
        "print(the)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_vectors.save('vectors.kv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTZrG4pXco_b"
      },
      "source": [
        "What is the most similar word for \"town\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Y7Rr8Hktco_d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('village', 0.8716565370559692), ('neighborhood', 0.8066190481185913), ('shop', 0.7781926393508911), ('city', 0.7741052508354187), ('hotel', 0.773698091506958), ('park', 0.7701700329780579), ('house', 0.7677633166313171), ('hut', 0.7621951103210449), ('prison', 0.7501834034919739), ('california', 0.7441031336784363)]\n"
          ]
        }
      ],
      "source": [
        "#YOUR CODE\n",
        "similar_to_town = word_vectors.similar_by_word(\"town\")\n",
        "print(similar_to_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv5QMF4gco_f"
      },
      "source": [
        "How similar are the words \"town\" and \"house\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "d3DwXOLeco_g"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE\n",
        "similarity_house_town = word_vectors.similarity(\"town\", \"house\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7677634\n"
          ]
        }
      ],
      "source": [
        "print(similarity_house_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7I5G-KpqbfH"
      },
      "source": [
        "<h4>Exercise 4.1 (3 Points)</h4>\n",
        "Now that we have trained our own embedding, lets test some classical ideas: \n",
        "implement the following formula. Print out the 10 words, that are most similar to this formula: <br>\n",
        "$King-Man+Woman=???$\n",
        "There are two ways of computing similarity in word Embeddings:\n",
        " - https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
        " - https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar_cosmul.html\n",
        "You should try out both! In this case one of them is better, but both of them are valid methods for computing similarity in the word-space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0y_5MLlqiMx"
      },
      "outputs": [],
      "source": [
        "#Your Implementation goes here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMlPdqqZco_i"
      },
      "source": [
        "<h4>Exercise 4.2 (2 Points)</h4>\n",
        "The expected outcome (Queen) should be one of the top ten most similar words. But there are also a lot of words, that you would not expect. Think about where how these words might be connected to the formula. Take your time and understand why some of the words (luther, mary, dr, president) might be in this list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snfyuAn3iraJ"
      },
      "source": [
        "YOUR ANSWER GOES HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMtpPOVtaBup"
      },
      "source": [
        "#### t-SNE visualization\n",
        "\n",
        "We will use the t-SNE algorithm, given belwo, for visualization. The so-called t-Distributed Stochastic Neighbor Embedding (t-SNE) is an unsupervised and non-linear machine learning technique. It is commonly used for visualizing high dimensional data (just like our high dimensional vectors). You do not have to understand the code, it's purpose is simply to give you an idea of how the data is arranged in high dimensional space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej8Ud778co_k"
      },
      "source": [
        "<h4>Exercise 4.3 (2 Points)</h4>\n",
        "To use the t-SNE code below, first put a list of the top 100 words (as strings) into a variable `words_top_ted`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xvlyyjf6co_m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[',', '.', 'the', 'and', 'to', 'of', 'a', 'that', 'i', 'in', 'it', 'you', 'we', 'is', \"'s\", 'this', 'so', 'they', 'was', 'for', 'are', 'have', 'but', 'what', 'do', 'on', 'with', '--', '?', 'one', \"n't\", 'can', 'about', 'there', 'be', 'as', 'not', 'at', 'all', 'my', \"''\", '``', 'people', \"'re\", 'like', 'if', 'from', ')', '(', 'now', 'our', ':', 'he', 'an', 'just', 'these', 'or', 'when', 'because', 'very', 'me', 'out', 'by', 'them', 'how', 'know', 'going', 'up', 'had', 'more', 'would', 'were', 'think', 'who', 'see', 'your', 'their', 'which', 'here', 'really', 'get', \"'ve\", 'then', 'two', \"'m\", 'us', 'world', 'some', 'time', 'has', 'laughter', 'could', 'actually', 'into', 'where', 'way', 'hundred', 'did', 'will', 'things']\n"
          ]
        }
      ],
      "source": [
        "#Your implementation goes here!\n",
        "words_top_ted = [word for word, freq in counts_ted_top1000tupels[:100]]\n",
        "print(words_top_ted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g8JIRw4co_n"
      },
      "source": [
        "The following code gets the corresponding vectors from the model, assuming it's called `model_ted`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-lLF1lZaBus",
        "outputId": "120e8597-a636-440e-ca76-b591eb4c2ab2"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"Key 'both' not present\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [137], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# This assumes words_top_ted is a list of strings, the top 250 words\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m words_top_vec_ted \u001b[39m=\u001b[39m [word_vectors[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mword\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words_top_ted]\n",
            "Cell \u001b[0;32mIn [137], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# This assumes words_top_ted is a list of strings, the top 250 words\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m words_top_vec_ted \u001b[39m=\u001b[39m [word_vectors[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mword\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words_top_ted]\n",
            "File \u001b[0;32m~/miniforge3/envs/iannwtf/lib/python3.10/site-packages/gensim/models/keyedvectors.py:404\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \n\u001b[1;32m    402\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 404\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[1;32m    406\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
            "File \u001b[0;32m~/miniforge3/envs/iannwtf/lib/python3.10/site-packages/gensim/models/keyedvectors.py:447\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    424\u001b[0m     \u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[1;32m    449\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
            "File \u001b[0;32m~/miniforge3/envs/iannwtf/lib/python3.10/site-packages/gensim/models/keyedvectors.py:421\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[1;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'both' not present\""
          ]
        }
      ],
      "source": [
        "# This assumes words_top_ted is a list of strings, the top 250 words\n",
        "words_top_vec_ted = [word_vectors[f\"{word}\"] for word in words_top_ted]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SgjCkvCco_p"
      },
      "source": [
        "The next few lines are for the t-SNE visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeJF5ut9aBux"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanifold\u001b[39;00m \u001b[39mimport\u001b[39;00m TSNE \n\u001b[1;32m      2\u001b[0m tsne \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m words_top_ted_tsne \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39mfit_transform(words_top_vec_ted)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE \n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "words_top_ted_tsne = tsne.fit_transform(words_top_vec_ted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2VgYLIZaBu2",
        "outputId": "0b9bbab8-6544-437b-a729-1cc4ebdc3d1d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'words_top_ted_tsne' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [139], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m p \u001b[39m=\u001b[39m figure(tools\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpan,wheel_zoom,reset,save\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m            toolbar_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mabove\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m            title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mword2vec T-SNE for most common words\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m source \u001b[39m=\u001b[39m ColumnDataSource(data\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(x1\u001b[39m=\u001b[39mwords_top_ted_tsne[:,\u001b[39m0\u001b[39m],\n\u001b[1;32m      6\u001b[0m                                     x2\u001b[39m=\u001b[39mwords_top_ted_tsne[:,\u001b[39m1\u001b[39m],\n\u001b[1;32m      7\u001b[0m                                     names\u001b[39m=\u001b[39mwords_top_ted))\n\u001b[1;32m      9\u001b[0m p\u001b[39m.\u001b[39mscatter(x\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx1\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx2\u001b[39m\u001b[39m\"\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, source\u001b[39m=\u001b[39msource)\n\u001b[1;32m     11\u001b[0m labels \u001b[39m=\u001b[39m LabelSet(x\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx1\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx2\u001b[39m\u001b[39m\"\u001b[39m, text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, y_offset\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[1;32m     12\u001b[0m                   text_font_size\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m8pt\u001b[39m\u001b[39m\"\u001b[39m, text_color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m#555555\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                   source\u001b[39m=\u001b[39msource, text_align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'words_top_ted_tsne' is not defined"
          ]
        }
      ],
      "source": [
        "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
        "           toolbar_location=\"above\",\n",
        "           title=\"word2vec T-SNE for most common words\")\n",
        "\n",
        "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
        "                                    x2=words_top_ted_tsne[:,1],\n",
        "                                    names=words_top_ted))\n",
        "\n",
        "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
        "\n",
        "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
        "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('iannwtf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "a3449bbb043929c6f13b514689ff91c66257e0787e2d8bb0eba8270d3f40eacf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
