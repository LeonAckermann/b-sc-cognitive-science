{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "\n",
    "# magic line only needed in jupyter notebooks!\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with as_supervised=True to import labels\n",
    "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "train_ds = mnist[0]\n",
    "val_ds = mnist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None, 19), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# 2. write function to create the dataset that we want\n",
    "def preprocess(data, batch_size, task):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    \n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    data = tf.data.Dataset.zip((data.shuffle(2000), data.shuffle(2000)))\n",
    "    \n",
    "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
    "    if(task==1):\n",
    "        data = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]+x2[1]>=5))\n",
    "        # transform boolean target to int\n",
    "        data = data.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    else:\n",
    "        # possible 19 results for a-b [-9, 9], encode as one hot vector for classification\n",
    "        data = data.map(lambda x1, x2: (x1[0], x2[0], tf.one_hot((x1[1]-x2[1]), 19, dtype=tf.float32)))\n",
    "    \n",
    "    # batch the dataset\n",
    "    data = data.batch(batch_size)\n",
    "    # prefetch\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "train_ds1 = preprocess(train_ds, batch_size=32, task=1) #train_ds.apply(preprocess)\n",
    "val_ds1 = preprocess(val_ds, batch_size=32, task=1) #val_ds.apply(preprocess)\n",
    "\n",
    "train_ds2 = preprocess(train_ds, batch_size=32, task=2) #train_ds.apply(preprocess)+\n",
    "val_ds2 = preprocess(val_ds, batch_size=32, task=2) #val_ds.apply(preprocess)\n",
    "print(train_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"), tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "        # layers to encode the images (both layers used for both images)\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.out_layer = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "        combined_x = self.dense3(combined_x)\n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "        # layers to encode the images (both layers used for both images)\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        \n",
    "        self.dense3 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        \n",
    "        self.out_layer = tf.keras.layers.Dense(19,activation=tf.nn.softmax)\n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "        combined_x = self.dense3(combined_x)\n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    # 5. train step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "    # 6. test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    return train_summary_writer, val_summary_writer\n",
    "\n",
    "train_summary_writer_subtask1, val_summary_writer_subtask1 = create_summary_writers(config_name=\"subtask_1_RUN1\")\n",
    "train_summary_writer_subtask2, val_summary_writer_subtask2 = create_summary_writers(config_name=\"subtask_2_RUN1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def training_loop(model, train_ds, val_ds, start_epoch,\n",
    "                  epochs, train_summary_writer, \n",
    "                  val_summary_writer, save_path):\n",
    "\n",
    "    # 1. iterate over epochs\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # 2. train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "        ## Training data\n",
    "        # 3. log and print training metrics\n",
    "        with train_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "        \n",
    "        #print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        \n",
    "        # 4. reset metric objects, only reset now after \n",
    "        model.reset_metrics()\n",
    "\n",
    "        #####################################################\n",
    "\n",
    "        ## Validation data\n",
    "        # 5. evaluate on validation data\n",
    "        for data in val_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "        # 6. log validation metrics\n",
    "        with val_summary_writer.as_default():\n",
    "            # for scalar metrics:\n",
    "            for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=e)\n",
    "            # alternatively, log metrics individually (allows for non-scalar metrics such as tf.keras.metrics.MeanTensor)\n",
    "            # e.g. tf.summary.image(name=\"mean_activation_layer3\", data = metrics[\"mean_activation_layer3\"],step=e)\n",
    "            \n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "        # 7. reset metric objects\n",
    "        model.reset_metrics()\n",
    "        \n",
    "    # 8. save model weights if save_path is given\n",
    "    if save_path:\n",
    "        model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-28c7459617f7338e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-28c7459617f7338e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]2022-11-26 17:01:18.702971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 1875/1875 [00:22<00:00, 84.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12470000237226486', 'loss: 929476.8125']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 17:01:40.743775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-26 17:01:43.470262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val_accuracy: 0.028800001367926598', 'val_loss: 3265666.5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.11973333358764648', 'loss: 11808498.0']\n",
      "['val_accuracy: 0.5501000285148621', 'val_loss: 32123520.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 95.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.1218833327293396', 'loss: 39904636.0']\n",
      "['val_accuracy: 0.0', 'val_loss: 88164768.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12343333661556244', 'loss: 83559032.0']\n",
      "['val_accuracy: 0.549500048160553', 'val_loss: 67226880.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.1205499991774559', 'loss: 142675264.0']\n",
      "['val_accuracy: 0.0', 'val_loss: 145255664.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12361666560173035', 'loss: 224616240.0']\n",
      "['val_accuracy: 0.09290000796318054', 'val_loss: 198728048.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 96.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12430000305175781', 'loss: 319855104.0']\n",
      "['val_accuracy: 0.0642000064253807', 'val_loss: 330234816.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 95.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12346667051315308', 'loss: 453290048.0']\n",
      "['val_accuracy: 0.06130000203847885', 'val_loss: 581762496.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 94.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.11933333426713943', 'loss: 602365120.0']\n",
      "['val_accuracy: 0.5482000112533569', 'val_loss: 645170880.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 95.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy: 0.12038333714008331', 'loss: 807302400.0']\n",
      "['val_accuracy: 0.020900001749396324', 'val_loss: 1198821248.0']\n"
     ]
    }
   ],
   "source": [
    "# 1. instantiate model\n",
    "model_subtask1 = BinaryModel()\n",
    "model_subtask2 = CategoricalModel()\n",
    "\n",
    "# 2. choose a path to save the weights\n",
    "save_path_subtask1 = \"subtask1_trained_model_RUN1\"\n",
    "save_path_subtask2 = \"subtask2_trained_model_RUN1\"\n",
    "\n",
    "# 3. pass arguments to training loop function\n",
    "training_loop(model=model_subtask2,\n",
    "    train_ds=train_ds2,\n",
    "    val_ds=val_ds2,\n",
    "    start_epoch=0,\n",
    "    epochs=10,\n",
    "    train_summary_writer=train_summary_writer_subtask2,\n",
    "    val_summary_writer=val_summary_writer_subtask2,\n",
    "    save_path=save_path_subtask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model:\n",
    "fresh_model = TwinMNISTModel()\n",
    "\n",
    "# build the model's parameters by calling it on input\n",
    "for img1,img2,label in train_ds:\n",
    "    fresh_model((img1,img2));\n",
    "    break\n",
    "\n",
    "# load the saved weights\n",
    "model = fresh_model.load_weights(save_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
